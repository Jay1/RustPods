---
description: This document outlines our test-driven approach for the RustPods project, covering unit tests, inteThis document outlines our test-driven approach for the RustPods project, covering unit tests, integration tests, and UI component testing patternsgration tests, and UI component testing patterns
globs: 
alwaysApply: false
---
# Testing Guidelines for RustPods

This document outlines our test-driven approach for the RustPods project, covering unit tests, integration tests, and UI component testing patterns.

## Testing Structure

- **Test Organization:**
  - Place unit tests in `#[cfg(test)]` modules at the end of each source file
  - Place integration tests in the `tests/` directory at the project root
  - Group related integration test files into descriptively named subdirectories within the tests/ directory
  - Name integration test files descriptively with a focus on functionality (e.g., `scanning.rs`, `filtering.rs`)
  - Group related tests within files into descriptively named submodules
  - For each test subdirectory, a `mod.rs` file can be used if you intend to group multiple test files within that subdirectory into a single, larger test crate. If mod.rs is absent, or if it does not declare other files as modules, each .rs file in the subdirectory will be compiled as an independent test crate. The tests/mod.rs at the root of the tests directory can be used to declare modules corresponding to the subdirectories if you wish to organize shared test logic or run all tests under a common test suite structure, but individual .rs files will still be discoverable as separate test crates by Cargo.

- **Implemented Structure:**
  ```
  tests/
  ├── mod.rs                     # Main test module declaration
  ├── common_test_helpers.rs     # Shared test utilities across all tests
  ├── app_config_tests.rs        # App-level tests
  ├── system_tray_tests.rs       # System tray tests
  ├── bluetooth/                 # Bluetooth-related tests
  │   ├── mod.rs                 # Bluetooth module declaration
  │   ├── common_utils.rs        # Bluetooth-specific test utilities
  │   ├── adapter.rs             # Bluetooth adapter tests
  │   ├── battery_status.rs      # AirPods battery tests
  │   ├── config.rs              # Scanner configuration tests
  │   ├── detection.rs           # AirPods detection tests
  │   ├── filtering.rs           # BLE filtering tests
  │   └── scanning.rs            # BLE scanning tests
  ├── event_system/              # Event system tests
  │   ├── mod.rs                 # Event system module declaration
  │   ├── broker.rs              # Event broker tests
  │   ├── core.rs                # Core event system tests
  │   ├── enhanced_broker.rs     # Advanced broker tests
  │   └── simple_broker.rs       # Simple broker tests
  └── ui/                        # UI component tests
      ├── mod.rs                 # UI module declaration
      ├── components.rs          # UI component tests
      ├── device_display.rs      # Device display tests
      ├── integration.rs         # UI integration tests
      ├── messages.rs            # UI message tests
      ├── rendering.rs           # UI rendering tests
      └── state.rs               # UI state tests
  ```

## Testing Principles

- **Independence:**
  - Tests should be able to run independently
  - Avoid shared mutable state between tests
  - Use test fixtures for common setup/teardown

- **Test Specific Behaviors:**
  - Focus tests on specific behaviors rather than general functionality
  - Name tests to reflect what they're specifically testing
  - Follow the pattern: `test_<function/component>_<scenario>_<expected_result>`

- **Mock Dependencies:**
  - Use `mockall` for creating mock objects
  - Inject mock dependencies in unit tests
  - Test real integrations in integration tests

## Test File Categories

- **Common Helpers:**
  - Place shared test utilities in `tests/common_test_helpers.rs`
  - Place domain-specific helpers in each subdirectory (e.g., `bluetooth/common_utils.rs`)

- **Bluetooth Tests:**
  - Basic functionality tests for Bluetooth scanners and adapters
  - Advanced feature tests for filtering, device detection, and status updates
  - Configuration validation tests

- **Event System Tests:**
  - Event broker initialization and lifecycle tests
  - Subscription and filtering tests
  - Event distribution and handling tests

- **UI Tests:**
  - Component rendering tests
  - State management tests
  - User interaction tests
  - Integration tests with backend functionality

## Testing Best Practices

- **Standardize Test Setup:**
  - Use consistent patterns for test setup across similar tests
  - Include helper functions for common operations
  - Document when and why to use each helper function

- **Test Edge Cases:**
  - Test error conditions and recovery mechanisms
  - Test boundary conditions in input validation
  - Test resource limits and timeouts

- **Avoid Brittle Tests:**
  - Don't rely on timing-sensitive operations
  - Use deterministic setup rather than random values
  - Parameterize tests for different inputs when appropriate

## Asynchronous Testing Guidelines

- **Always Use Timeouts:**
  - Wrap asynchronous operations with timeouts to prevent hanging tests
  - Use `tokio::time::timeout` or the provided `with_timeout` helper function
  - Example:
    ```rust
    // Instead of:
    let result = async_operation().await;
    
    // Do this:
    let result = match timeout(Duration::from_millis(1000), async_operation()).await {
        Ok(res) => res,
        Err(_) => panic!("Operation timed out"),
    };
    ```

- **Stream Testing:**
  - Convert channels to streams for better testability with `receiver_to_stream`
  - Use `pin_mut!` to pin streams in place
  - Test stream completion explicitly
  - Avoid waiting indefinitely for stream values

- **Resource Cleanup:**
  - Ensure proper cleanup in async tests with `Drop` implementations
  - Use `task.abort()` to cancel background tasks in tests
  - Clean up channels and other resources even on test failure
  - Add timeouts to shutdown operations

## Test Dependency Management

- **Required Crates:**
  - Add `tokio-stream` to dev-dependencies for stream testing
  - Use `mockall` for mocking dependencies
  - Use `pretty_assertions` for improved assertion failure messages
  - Use `tempfile` for file system testing

- **Feature Flags:**
  - Define test-specific feature flags for optional test functionality
  - Example: `stream_testing` or `fs_testing`

## Test Annotations

- **Test Attributes:**
  - Use `#[tokio::test]` for async tests
  - Use `#[test]` for synchronous tests
  - Add `#[ignore]` for long-running or resource-intensive tests
  - Add `#[should_panic]` for tests that verify panics

- **Test Categories:**
  - Add comments to group related tests
  - Document test purpose when not obvious from the name

## Test Documentation

- **Test Comments:**
  - Clearly document test setup, assumptions, and expected outcomes
  - Group test cases logically using comment headers
  - Explain complex test scenarios or edge cases being tested

- **Test Helper Documentation:**
  - Document each test helper function with descriptive comments
  - Explain parameter requirements and return values
  - Note any side effects or required state

## Edge Cases to Test

- **Concurrency:**
  - Test race conditions between event consumers
  - Test cancellation and cleanup during operations
  - Test graceful shutdown behavior

- **Resource Limits:**
  - Test behavior with channel buffer full
  - Test recovery when resources are exhausted
  - Test operation timeouts

- **Error Handling:**
  - Test error propagation across component boundaries
  - Test recovery after errors
  - Test logging and reporting of errors

## Unit Testing Guidelines

- **Core Components Testing:**
  - Every public function should have at least one unit test
  - Test both expected success cases and expected failure cases
  - Create meaningful test data that resembles real-world scenarios
  - For complex functions, test edge cases and boundary conditions

- **Helper Utilities:**
  - Create test helper functions for frequently used test setup code
  - Place helper functions at the top of the test module
  - Document helper functions with clear descriptions

```rust
#[cfg(test)]
mod tests {
    use super::*;
    
    // Helper to create a test device with manufacturer data
    fn create_test_device_with_data(
        address: [u8; 6],
        name: Option<&str>,
        rssi: Option<i16>,
        manufacturer_data: HashMap<u16, Vec<u8>>
    ) -> DiscoveredDevice {
        DiscoveredDevice {
            address: BDAddr::from(address),
            name: name.map(|s| s.to_string()),
            rssi,
            manufacturer_data,
            is_potential_airpods: false,
            last_seen: Instant::now(),
        }
    }
    
    #[test]
    fn test_function_behavior() {
        // Test code using helper function
        let device = create_test_device_with_data(...);
        assert_eq!(function_under_test(device), expected_result);
    }
}
```

## Integration Testing Guidelines

- **Cross-Module Interaction:**
  - Test interactions between multiple components
  - Verify that modules integrate correctly with each other
  - Focus on testing complete user scenarios
  - Use real implementations rather than mocks when practical

- **Bluetooth Testing:**
  - Test adapter discovery and management
  - Test device scanning functionality
  - Test filtering of discovered devices
  - Test event generation and handling
  - Verify correct behavior with different scan configurations

```rust
#[tokio::test]
async fn test_scan_with_filter() {
    let mut scanner = BleScanner::new().await.unwrap();
    let config = ScanConfig::airpods_optimized();
    
    scanner.set_config(config);
    
    // Start scanning with a filter
    let filter = create_airpods_filter();
    let filtered_devices = scanner.scan_with_filter(filter).await.unwrap();
    
    // Verify filtered results
    for device in filtered_devices {
        assert!(device.is_potential_airpods);
    }
}
```

- **Event System Testing:**
  - Test event generation from Bluetooth operations
  - Test event filtering with different filter types
  - Test event subscription and delivery
  - Test event broker management of multiple subscribers
  - Verify concurrent handling of events
  - Use timeout-based testing for asynchronous events

```rust
#[tokio::test]
async fn test_event_broker_filter_by_type() {
    // Create an event broker
    let mut broker = EventBroker::new();
    broker.start();
    
    // Subscribe to only AirPods events
    let (subscriber_id, rx) = broker.subscribe(EventFilter::event_types(vec![EventType::AirPodsDetected]));
    let stream = receiver_to_stream(rx);
    pin_mut!(stream);
    
    // Send a device discovery event (should be filtered out)
    let device_event = BleEvent::DeviceDiscovered(create_test_device(...));
    broker.get_sender().send(device_event).await.unwrap();
    
    // Send an AirPods event (should be received)
    let airpods_event = BleEvent::AirPodsDetected(create_test_airpods(...));
    broker.get_sender().send(airpods_event).await.unwrap();
    
    // The subscriber should receive only the AirPods event
    let received = timeout(Duration::from_millis(100), stream.next()).await;
    assert!(received.is_ok(), "Should receive the AirPods event");
    
    match received.unwrap().unwrap() {
        BleEvent::AirPodsDetected(_) => { /* Expected */ },
        _ => panic!("Received unexpected event type"),
    }
    
    // Should not receive any more events
    let no_more_events = timeout(Duration::from_millis(100), stream.next()).await;
    assert!(no_more_events.is_err(), "Should not receive any more events");
}
```

- **AirPods Detection Testing:**
  - Test identification of different AirPods models
  - Test parsing of manufacturer data
  - Test battery level extraction and processing
  - Test charging status detection
  - Verify handling of invalid or non-AirPods data

```rust
#[test]
fn test_detect_airpods_pro() {
    // Create manufacturer data for AirPods Pro
    let mut manufacturer_data = HashMap::new();
    manufacturer_data.insert(
        APPLE_COMPANY_ID,
        create_airpods_data(AIRPODS_PRO_PREFIX, 9, 9, 5, 0b00000110) // 90%, 90%, 50%, left+right charging
    );
    
    let device = create_test_device_with_data(
        [0x02, 0x03, 0x04, 0x05, 0x06, 0x07],
        Some("AirPods Pro"),
        Some(-65),
        manufacturer_data
    );
    
    // Test detection
    let result = detect_airpods(&device);
    assert!(result.is_some(), "Should detect AirPods Pro device");
    
    let airpods = result.unwrap();
    assert_eq!(airpods.device_type, AirPodsType::AirPodsPro);
    assert_eq!(airpods.battery.left, Some(90));
    assert_eq!(airpods.battery.right, Some(90));
    assert_eq!(airpods.battery.case, Some(50));
    assert!(airpods.battery.charging.left);
    assert!(airpods.battery.charging.right);
    assert!(!airpods.battery.charging.case);
}
```

## UI Testing Guidelines

- **UI State Testing:**
  - Test initialization of UI state
  - Test state transitions from user actions
  - Test handling of UI messages
  - Test data flow between UI and application logic
  - Verify correct message handling behavior

```rust
#[test]
fn test_app_state_message_handling() {
    let mut app_state = AppState::new();
    
    // Test UI message handling
    app_state.update(Message::StartScan);
    assert!(app_state.is_scanning);
    
    app_state.update(Message::StopScan);
    assert!(!app_state.is_scanning);
    
    // Test data flow
    let device = create_test_device([1, 2, 3, 4, 5, 6], "Test Device", -60);
    app_state.update(Message::DeviceDiscovered(device.clone()));
    assert_eq!(app_state.devices.len(), 1);
}
```

- **UI Component Testing:**
  - Test individual UI components in isolation
  - Verify correct rendering with different input states
  - Test component interactions and state updates
  - Verify accessibility features work correctly
  - Test UI responsiveness to different window sizes

- **Iced Framework Testing:**
  - Test component integration with Iced
  - Verify correct subscription behavior
  - Test message passing between components
  - Verify UI updates in response to application events

## System Tray Testing

- **Headless Testing:**
  - Focus on testing the API structure rather than actual GUI interactions
  - Test message passing through channels
  - Test error handling and recovery paths
  - Use TypeId verification for type checking when actual instances can't be created

```rust
#[test]
fn test_system_tray_api() {
    // Create a message channel
    let (tx, _rx) = mpsc::channel::<Message>();
    
    // Verify the error enum functionality
    
    // Instead of actually creating a tray (which would fail in CI),
    // verify type API is correctly defined
    let type_id = std::any::TypeId::of::<SystemTray>();
    assert_eq!(type_id, std::any::TypeId::of::<SystemTray>());
    
    // Test sending messages on the channel
    let result = tx.send(Message::ToggleVisibility);
    assert!(result.is_ok(), "Should be able to send messages on the channel");
}
```

- **Message Handling:**
  - Test that UI message enum variants are correctly implemented
  - Verify that message patterns can be properly matched
  - Test debug formatting for messages
  - Ensure messages can be correctly sent through channels

## Configuration Testing

- **AppConfig Testing:**
  - Test default configuration values
  - Test conversion to specialized configs (e.g., ScanConfig)
  - Test custom configuration creation and validation
  - Test configuration serialization and deserialization
  - Verify platform-specific path handling

```rust
#[test]
fn test_custom_config() {
    // Create a fully custom config
    let custom_config = AppConfig {
        auto_scan_on_startup: false,
        scan_duration: Duration::from_secs(15),
        scan_interval: Duration::from_secs(45),
        min_rssi: Some(-55),
        show_notifications: false,
        start_minimized: false,
        theme: Theme::Dark,
        settings_path: PathBuf::from("/custom/path/settings.json"),
    };
    
    // Verify all custom values
    assert!(!custom_config.auto_scan_on_startup);
    assert_eq!(custom_config.scan_duration, Duration::from_secs(15));
    
    // Test converting to ScanConfig
    let scan_config = custom_config.to_scan_config();
    assert_eq!(scan_config.scan_duration, Duration::from_secs(15));
}
```

## Platform-Specific Testing

- **Conditional Compilation:**
  - Use `#[cfg(target_os = "windows")]` for Windows-specific tests
  - Use `#[cfg(target_family = "unix")]` for Unix-based systems (macOS, Linux)
  - Implement platform-specific validation where needed
  - Test platform-specific paths and configurations

```rust
// Verify the path points to a valid location
let path = &config.settings_path;
assert!(path.to_str().is_some(), "Path should be convertible to a string");

// For Windows, expect a path that includes AppData
#[cfg(target_os = "windows")]
assert!(path.to_str().unwrap().contains("config") || 
        path.to_str().unwrap().contains("Config") ||
        path.to_str().unwrap().contains("AppData"),
        "Windows path should contain config or AppData directory");

// For Unix systems, should include .config
#[cfg(target_family = "unix")]
assert!(path.to_str().unwrap().contains(".config"), 
        "Unix path should contain .config directory");
```

- **Cross-Platform Adaptation:**
  - Skip tests that aren't compatible with all platforms
  - Provide alternative test paths for different platforms
  - Document platform-specific limitations in test comments

## Mock Testing Patterns

- **UI Mocking Approach:**
  - Create test doubles for UI components that can't be tested in headless environments
  - Test message handling logic without requiring actual UI rendering
  - Verify UI state transitions using mocked user input

```rust
#[test]
fn test_ui_state_with_mocked_input() {
    // Create the UI state
    let mut state = AppState::default();
    
    // Simulate a user action by sending a message directly
    state.update(Message::SelectDevice("test-device-id".to_string()));
    
    // Verify the state changed correctly
    assert_eq!(state.selected_device, Some("test-device-id".to_string()));
}
```

- **Bluetooth Mocking:**
  - Create mock Bluetooth adapters for testing scanning logic
  - Generate synthetic device discovery events
  - Simulate various connection scenarios
  - Test error handling with artificially induced failures

```rust
#[test]
fn test_bluetooth_error_handling() {
    // Create a mock adapter that always fails to scan
    let mock_adapter = MockAdapter::new().with_scan_error(BleError::ScanInProgress);
    
    // Test that the error is properly handled
    let result = process_scan_with_adapter(&mock_adapter);
    assert!(matches!(result, Err(RustPodsError::BluetoothError(_))));
}
```

## Test Data Management

- **Test Data Factories:**
  - Create dedicated functions to generate test data
  - Parameterize test data generation for different scenarios
  - Document the purpose and structure of test data

```rust
/// Helper to create test AirPods manufacturer data with the correct format
fn create_airpods_data(
    prefix: &[u8],
    left_battery: u8,
    right_battery: u8,
    case_battery: u8,
    charging_status: u8
) -> Vec<u8> {
    // The data structure must exactly match what's expected in parse_airpods_data
    let mut data = Vec::with_capacity(27);
    
    // AirPods model prefix (first two bytes)
    data.push(prefix[0]);
    data.push(prefix[1]);
    
    // Add 10 bytes of dummy data
    data.extend_from_slice(&[0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08, 0x09, 0x0A]);
    
    // Add battery and status data
    data.push(left_battery);
    data.push(right_battery);
    data.push(charging_status);
    data.push(case_battery);
    
    // Add padding
    data.extend_from_slice(&[0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00]);
    
    data
}
```

## Continuous Integration Considerations

- **CI Environment Testing:**
  - Ensure tests can run in headless environments (GitHub Actions, etc.)
  - Skip UI/system tray tests that require a display server
  - Use conditional compilation to adapt to CI environments
  - Add CI-specific test flags where needed

```rust
// Skip tests that require a display server in CI environments
#[test]
#[cfg_attr(feature = "ci", ignore)]
fn test_requires_display_server() {
    // Test that would fail in a headless CI environment
}
```

- **Test Tagging and Organization:**
  - Use `#[ignore]` for tests that are long-running or require special setup
  - Group related tests with modules or helper functions
  - Document test dependencies and requirements
  - Use descriptive test names that explain the purpose of the test
















